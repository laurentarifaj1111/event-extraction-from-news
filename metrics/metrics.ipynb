{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+I5J5RtuhSUG7yq9WLJ7Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["MODEL = 't5-base'\n","BATCH_SIZE = 8\n","NUM_PROCS = 4\n","EPOCHS = 10\n","# OUT_DIR = 'results_t5base/2k_samples'\n","OUT_DIR = 'results_t5_large_regularized/10k_samples_fixed'\n","MAX_LENGTH = 1024 # Maximum context length to consider while preparing dataset.\n","epoch_metrics = []\n","DRIVE_DATA_PATH = \"/content/drive/MyDrive/processed/10k_samples\"   # UPDATE PATH\n","CLEAN_TEXT_COLUMN='article'\n","SUMMARY_COLUMN='highlights'"],"metadata":{"id":"RctCKn0a2Mgt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorboard\n","!pip install tensorboard-data-server\n","!pip install google-cloud-storage\n","!pip install tbparse matplotlib seaborn pandas numpy\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHGdehOv2W9v","outputId":"4e68c735-0fed-46b1-87bd-9925103b6a2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vwPmrryU1tgY"},"outputs":[],"source":["# from google.colab import auth\n","# auth.authenticate_user()"]},{"cell_type":"code","source":["# !mkdir -p /content/fixed_logs/\n","# !gsutil -m cp -r gs://models_checkpoint/models/results_t5_base_fixed/2k_samples/* /content/fixed_logs/"],"metadata":{"id":"61rMx4Z64zcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","# Install gcsfuse\n","!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n","!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n","!apt -qq update\n","!apt -qq install gcsfuse\n","\n","# Create a local directory for mounting\n","!mkdir results_t5_base_regularized\n","# models_regularized_run/models/results_t5_base/2k_samples\n","# Mount the GCS bucket\n","# Replace 'your-bucket-name' with the actual name of your GCS bucket\n","!gcsfuse --implicit-dirs models_regularized_run results_t5_base_regularized"],"metadata":{"id":"ZwWQz0HAURn0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example run directories\n","# models_regularized_run/models/results_t5_base/2k_samples\n","RUNS = {\n","    \"t5_2k\": \"/content/results_t5_base_regularized/models/results_t5_base/2k_samples\",\n","    # add more runs here\n","}"],"metadata":{"id":"wEFxinRb8Vff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from tbparse import SummaryReader\n","import os\n","\n","def load_run(run_path):\n","    reader = SummaryReader(run_path)\n","    df = reader.scalars  # TensorBoard scalars\n","    return df\n"],"metadata":{"id":"rYgHkbuo876X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_metrics(run_name, run_path):\n","    import os\n","    import pandas as pd\n","    from tbparse import SummaryReader\n","\n","    # Read event logs (auto-detect format: long or wide)\n","    reader = SummaryReader(run_path)\n","    df = reader.scalars\n","\n","    # Detect long vs wide format\n","    is_long_format = \"tag\" in df.columns\n","\n","    # Helper to extract values for a given tag in both formats\n","    def get_values(tag):\n","        if is_long_format:\n","            sub = df[df[\"tag\"] == tag]\n","            return sub[[\"step\", \"value\"]] if not sub.empty else None\n","        else:\n","            if tag in df.columns:\n","                # wide format: 'step' + tag column\n","                sub = df[[\"step\", tag]].dropna()\n","                sub = sub.rename(columns={tag: \"value\"})\n","                return sub if not sub.empty else None\n","            else:\n","                return None\n","\n","    # --- 1. TRAIN LOSS ---\n","    train_loss_raw = get_values(\"train/loss\")\n","    if train_loss_raw is not None:\n","        train_loss = pd.DataFrame({\n","            \"step\": train_loss_raw[\"step\"].values,\n","            \"loss\": train_loss_raw[\"value\"].values\n","        })\n","    else:\n","        train_loss = None\n","\n","    # --- 2. VALIDATION LOSS ---\n","    val_loss_raw = get_values(\"eval/loss\")\n","    if val_loss_raw is not None:\n","        val_loss = pd.DataFrame({\n","            \"step\": val_loss_raw[\"step\"].values,\n","            \"loss\": val_loss_raw[\"value\"].values\n","        })\n","    else:\n","        val_loss = None\n","\n","    # --- 3. ROUGE METRICS ---\n","    def get_last_metric(tag):\n","        m = get_values(tag)\n","        return m[\"value\"].iloc[-1] if m is not None and not m.empty else None\n","\n","    rouge1 = get_last_metric(\"eval/rouge1\")\n","    rouge2 = get_last_metric(\"eval/rouge2\")\n","    rougeL = get_last_metric(\"eval/rougeL\")\n","\n","    # --- 4. GPU USAGE ---\n","    gpu_raw = get_values(\"gpu_memory_gb\")\n","    gpu_avg = gpu_raw[\"value\"].mean() if gpu_raw is not None else None\n","\n","    # --- 5. TRAINING TIME ---\n","    tt_raw = get_values(\"total_training_time_seconds\")\n","    train_time = tt_raw[\"value\"].iloc[0] if tt_raw is not None else None\n","\n","    # --- 6. HALLUCINATION ---\n","    hall_path = os.path.join(run_path, \"hallucination.csv\")\n","    if os.path.exists(hall_path):\n","        hall_df = pd.read_csv(hall_path)\n","        hallucination = hall_df[\"hallucination_rate\"].mean()\n","    else:\n","        hallucination = None\n","\n","    # --- FINAL OUTPUT ---\n","    return {\n","        \"run\": run_name,\n","        \"train_loss\": train_loss,  # <--- always normalized DataFrame\n","        \"val_loss\": val_loss,      # <--- always normalized DataFrame\n","        \"rouge1\": rouge1,\n","        \"rouge2\": rouge2,\n","        \"rougeL\": rougeL,\n","        \"gpu_avg\": gpu_avg,\n","        \"train_time_sec\": train_time,\n","        \"hallucination\": hallucination\n","    }\n"],"metadata":{"id":"P2Z_8aTs8cUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_metrics = []\n","\n","for run_name, run_path in RUNS.items():\n","    metrics = extract_metrics(run_name, run_path)\n","    all_metrics.append(metrics)\n","\n","summary_df = pd.DataFrame([{\n","    \"run\": m[\"run\"],\n","    \"rouge1\": m[\"rouge1\"],\n","    \"rouge2\": m[\"rouge2\"],\n","    \"rougeL\": m[\"rougeL\"],\n","    \"gpu_avg\": m[\"gpu_avg\"],\n","    \"train_time_min\": m[\"train_time_sec\"] / 60 if m[\"train_time_sec\"] else None,\n","    \"hallucination\": m[\"hallucination\"]\n","} for m in all_metrics])\n","\n","summary_df\n"],"metadata":{"id":"FbHxWoVz8eGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","for m in all_metrics:\n","    if m[\"train_loss\"] is None or m[\"val_loss\"] is None:\n","        continue\n","\n","    plt.figure(figsize=(10,6))\n","    plt.plot(m[\"train_loss\"][\"step\"], m[\"train_loss\"][\"loss\"], label=\"Train Loss\")\n","    plt.plot(m[\"val_loss\"][\"step\"], m[\"val_loss\"][\"loss\"], label=\"Validation Loss\")\n","\n","    plt.title(f\"Loss Curve for {m['run']}\")\n","    plt.xlabel(\"Step\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n"],"metadata":{"id":"oTecMvgfA2mp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","df_sorted = summary_df.sort_values(\"data_size\")\n","\n","plt.figure(figsize=(10,6))\n","plt.plot(df_sorted[\"data_size\"], df_sorted[\"rouge1\"], marker=\"o\", label=\"ROUGE-1\")\n","plt.plot(df_sorted[\"data_size\"], df_sorted[\"rouge2\"], marker=\"o\", label=\"ROUGE-2\")\n","plt.plot(df_sorted[\"data_size\"], df_sorted[\"rougeL\"], marker=\"o\", label=\"ROUGE-L\")\n","\n","plt.xscale(\"log\")\n","plt.xlabel(\"Training Data Size (log scale)\")\n","plt.ylabel(\"ROUGE Score\")\n","plt.title(\"ROUGE Score vs Training Data Size\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"1icaj5Xt_xRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","# Extract data size from run name (assumes \"t5_4k\")\n","summary_df[\"data_size\"] = summary_df[\"run\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"k\",\"000\")))\n","\n","plt.figure(figsize=(10,6))\n","plt.plot(summary_df[\"data_size\"], summary_df[\"rouge1\"], marker=\"o\", label=\"ROUGE-1\")\n","plt.plot(summary_df[\"data_size\"], summary_df[\"rouge2\"], marker=\"o\", label=\"ROUGE-2\")\n","plt.plot(summary_df[\"data_size\"], summary_df[\"rougeL\"], marker=\"o\", label=\"ROUGE-L\")\n","plt.xscale(\"log\")\n","plt.xlabel(\"Training Data Size (log-scale)\")\n","plt.ylabel(\"ROUGE Score\")\n","plt.legend()\n","plt.title(\"ROUGE vs Training Data Size\")\n","plt.show()\n"],"metadata":{"id":"-XhNOA6l8iC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,6))\n","sns.barplot(data=summary_df, x=\"run\", y=\"rouge1\")\n","plt.title(\"ROUGE-1 Across Models\")\n","plt.show()\n"],"metadata":{"id":"Cb5UKfPo8jnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","sns.barplot(data=summary_df, x=\"run\", y=\"hallucination\")\n","plt.title(\"Hallucination Rate by Model\")\n","plt.ylabel(\"Hallucination Rate\")\n","plt.show()\n"],"metadata":{"id":"44emhq4T8lTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax1 = plt.subplots(figsize=(10,6))\n","\n","ax1.bar(summary_df[\"run\"], summary_df[\"train_time_min\"], color=\"blue\", label=\"Training Time (min)\")\n","ax1.set_ylabel(\"Training Time (min)\", color=\"blue\")\n","\n","ax2 = ax1.twinx()\n","ax2.plot(summary_df[\"run\"], summary_df[\"gpu_avg\"], color=\"red\", marker=\"o\", label=\"GPU Memory (GB)\")\n","ax2.set_ylabel(\"GPU Memory (GB)\", color=\"red\")\n","\n","plt.title(\"Training Time and GPU Usage per Run\")\n","plt.show()\n"],"metadata":{"id":"ML1d2UF-8mkf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir /content/tb_logs\n"],"metadata":{"id":"gopAUlIa41NW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load data from Google Drive\n","import pandas as pd\n","\n","print(\"Loading data...\")\n","train_df = pd.read_csv(f\"{DRIVE_DATA_PATH}/train.csv\").head(2000)\n","val_df = pd.read_csv(f\"{DRIVE_DATA_PATH}/val.csv\").head(200)\n","# test_df = pd.read_csv(f\"{DRIVE_DATA_PATH}/test.csv\")\n","\n","# train_df, val_df = train_test_split(train_df, test_size=0.2, shuffle=True)\n","\n","# train_df = train_df.dropna(subset=['Summary', 'clean_text'])\n","# val_df = val_df.dropna(subset=['Summary', 'clean_text'])\n","\n","print(\"Train:\", len(train_df))\n","print(\"Val:\", len(val_df))\n","# print(\"Test:\", len(test_df))"],"metadata":{"id":"CKJjwwMp2KPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir $LOG_DIR"],"metadata":{"id":"pZj37K9o2SgC"},"execution_count":null,"outputs":[]}]}