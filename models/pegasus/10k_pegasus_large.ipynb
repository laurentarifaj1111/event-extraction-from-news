{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1765141515237,
     "user": {
      "displayName": "Laurent Arifaj",
      "userId": "09689383856083908659"
     },
     "user_tz": -60
    },
    "id": "EMIflcpRwSqn"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PEGASUS CNN/DAILYMAIL MODEL FINE-TUNING CONFIGURATION\n",
    "# ============================================================================\n",
    "# This notebook fine-tunes a Pegasus model pre-trained on CNN/DailyMail dataset.\n",
    "# The CNN/DailyMail variant is optimized for news article summarization.\n",
    "#\n",
    "# Configuration Parameters:\n",
    "# - MODEL: Pre-trained Pegasus model (google/pegasus-cnn_dailymail)\n",
    "# - OUT_DIR = # Directory to save model checkpoints and results\n",
    "# - DRIVE_DATA_PATH: Path to dataset in Google Drive (UPDATE THIS!)\n",
    "# - CLEAN_TEXT_COLUMN: Column name in CSV containing article text\n",
    "# - SUMMARY_COLUMN: Column name in CSV containing reference summaries\n",
    "# ============================================================================\n",
    "\n",
    "MODEL = 'google/pegasus-large'\n",
    "OUT_DIR = 'pegasus/10k_samples'\n",
    "DRIVE_DATA_PATH = \"/content/drive/MyDrive/processed/10k_samples\"\n",
    "CLEAN_TEXT_COLUMN = 'article'  \n",
    "SUMMARY_COLUMN = 'highlights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qvmepo9vNCqs"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: GOOGLE CLOUD STORAGE (GCS) SETUP\n",
    "# ============================================================================\n",
    "# This cell is optional - only needed if you want to save/load models from GCS.\n",
    "# If you're only using Google Drive, you can skip this cell.\n",
    "#\n",
    "# This sets up gcsfuse to mount a Google Cloud Storage bucket for model storage.\n",
    "# ============================================================================\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Install gcsfuse (Google Cloud Storage FUSE - allows mounting GCS buckets as filesystem)\n",
    "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "!apt -qq update\n",
    "!apt -qq install gcsfuse\n",
    "\n",
    "# Create a local directory for mounting the GCS bucket\n",
    "!mkdir -p pegasus\n",
    "\n",
    "# Mount the GCS bucket\n",
    "!gcsfuse --implicit-dirs pegasus_large_10k_2nd pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DubrCb8GwXyg"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MOUNT GOOGLE DRIVE\n",
    "# ============================================================================\n",
    "# This cell mounts your Google Drive to access your dataset files.\n",
    "# You'll be prompted to authorize access - follow the instructions.\n",
    "# ============================================================================\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWoALIEfzkzm"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers\n",
    "!pip install -U datasets\n",
    "!pip install tensorboard\n",
    "!pip install sentencepiece\n",
    "!pip install accelerate\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12302,
     "status": "ok",
     "timestamp": 1765141533305,
     "user": {
      "displayName": "Laurent Arifaj",
      "userId": "09689383856083908659"
     },
     "user_tz": -60
    },
    "id": "89nzRnGjz3CL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pprint\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import (\n",
    "    PegasusForConditionalGeneration,  Trainer, TrainingArguments,\n",
    "    PegasusTokenizer,EarlyStoppingCallback,T5ForConditionalGeneration, T5Tokenizer,\n",
    "    PegasusXForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1765141533308,
     "user": {
      "displayName": "Laurent Arifaj",
      "userId": "09689383856083908659"
     },
     "user_tz": -60
    },
    "id": "4NGDTnQ1wuHZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset=None, freeze_encoder=False, output_dir='./results'):\n",
    "  \"\"\"\n",
    "  Prepare configurations and base model for fine-tuning\n",
    "  \"\"\"\n",
    "  torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "  if freeze_encoder:\n",
    "    for param in model.model.encoder.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "  # Training configuration\n",
    "  training_args = Seq2SeqTrainingArguments(\n",
    "      output_dir=OUT_DIR,                 # Where to save checkpoints and outputs\n",
    "      num_train_epochs=10,                # Total number of training epochs\n",
    "\n",
    "      # Batch sizes (increased – adjust based on GPU memory)\n",
    "      per_device_train_batch_size=20,     # Training batch size per GPU\n",
    "      per_device_eval_batch_size=32,      # Evaluation batch size per GPU\n",
    "\n",
    "      # Checkpointing\n",
    "      save_strategy=\"epoch\",              # Save model at the end of each epoch\n",
    "\n",
    "      # Learning rate and optimization\n",
    "      learning_rate=1e-4,                 # Learning rate for fine-tuning\n",
    "      warmup_ratio=0.1,                   # Warmup over first 10% of training steps\n",
    "      weight_decay=0.01,                  # L2 regularization\n",
    "      gradient_accumulation_steps=8,      # Effective batch size = 20 × 8 = 160\n",
    "\n",
    "      # Logging and evaluation\n",
    "      logging_dir=f\"./{OUT_DIR}/logs\",        # TensorBoard log directory\n",
    "      logging_steps=200,                  # Log every N steps\n",
    "      logging_strategy=\"epoch\",           # Also log at the end of each epoch\n",
    "      evaluation_strategy=\"epoch\",        # Evaluate after each epoch\n",
    "      report_to=\"tensorboard\",            # Enable TensorBoard logging\n",
    "\n",
    "      # Generation settings (used during evaluation)\n",
    "      predict_with_generate=True,         # Generate summaries during evaluation\n",
    "\n",
    "      # Performance optimizations (A100 / modern GPUs)\n",
    "      bf16=True,                          # Use bfloat16 precision\n",
    "      fp16=False,                        # Disable fp16 (bf16 is more stable)\n",
    "      tf32=True,                         # Enable TensorFloat-32 on Ampere GPUs\n",
    "      torch_compile=True,                # Enable PyTorch compilation\n",
    "\n",
    "      # Model selection\n",
    "      metric_for_best_model=\"eval_loss\",  # Select best model using validation loss\n",
    "      greater_is_better=False,            # Lower loss is better\n",
    "      load_best_model_at_end=True,        # Load best model after training\n",
    "  )\n",
    "\n",
    "  trainer = Seq2SeqTrainer(\n",
    "      model=model,                  # Pretrained transformer model to be fine-tuned\n",
    "      args=training_args,           # TrainingArguments defined above\n",
    "      train_dataset=train_dataset,  # Dataset used for training\n",
    "      eval_dataset=val_dataset,     # Dataset used for validation / evaluation\n",
    "      tokenizer=tokenizer,          # Tokenizer for encoding and decoding text\n",
    "      compute_metrics=compute_metrics,  # Function to compute evaluation metrics\n",
    "      callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],# Stop training if validation loss does not improve\n",
    "  )\n",
    "\n",
    "  return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1765141533324,
     "user": {
      "displayName": "Laurent Arifaj",
      "userId": "09689383856083908659"
     },
     "user_tz": -60
    },
    "id": "--QyWKjbweCG"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TENSORBOARD LOGGING, DATASET CLASSES, AND UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "# This cell sets up TensorBoard logging, custom dataset class, GPU monitoring,\n",
    "# data preparation functions, and evaluation metrics computation.\n",
    "# ============================================================================\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import TrainerCallback\n",
    "import time\n",
    "\n",
    "# Initialize TensorBoard writer (logs will be saved to OUT_DIR)\n",
    "writer = SummaryWriter(log_dir=OUT_DIR)\n",
    "print(f\"TensorBoard logs will be saved to: {OUT_DIR}\")\n",
    "\n",
    "class PegasusDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset class for Pegasus model training.\n",
    "    \n",
    "    This class wraps tokenized encodings and labels into a format\n",
    "    that PyTorch DataLoader can use for efficient batching.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encodings: Tokenized input texts (dictionary with 'input_ids', 'attention_mask')\n",
    "            labels: Tokenized target summaries (dictionary with 'input_ids')\n",
    "        \"\"\"\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single training example.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with input_ids, attention_mask, and labels as tensors\n",
    "        \"\"\"\n",
    "        # Convert encodings to tensors\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Add labels (target summaries) as tensors\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of examples in the dataset.\"\"\"\n",
    "        return len(self.labels['input_ids'])\n",
    "\n",
    "class GpuLoggerCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Custom callback to log GPU memory usage during training.\n",
    "    \n",
    "    This helps monitor if you're running out of GPU memory and need to\n",
    "    reduce batch size or other memory-intensive settings.\n",
    "    \"\"\"\n",
    "    def __init__(self, writer):\n",
    "        self.writer = writer\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        \"\"\"\n",
    "        Called after each training step.\n",
    "        Logs current GPU memory usage to TensorBoard.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            # Get current GPU memory usage in GB\n",
    "            gpu_mem = torch.cuda.memory_allocated() / (1024 ** 3)\n",
    "            # Log to TensorBoard\n",
    "            self.writer.add_scalar(\"gpu_memory_gb\", gpu_mem, state.global_step)\n",
    "        return control\n",
    "\n",
    "def prepare_data(model_name,\n",
    "                 train_texts, train_labels,\n",
    "                 val_texts=None, val_labels=None,\n",
    "                 test_texts=None, test_labels=None):\n",
    "  \"\"\"\n",
    "  Prepare input data for model fine-tuning.\n",
    "  \n",
    "  This function tokenizes articles and summaries, creating datasets\n",
    "  ready for training.\n",
    "  \n",
    "  Args:\n",
    "    model_name: Name of the Pegasus model (for tokenizer)\n",
    "    train_texts: List of training article texts\n",
    "    train_labels: List of training summary texts\n",
    "    val_texts: List of validation article texts (optional)\n",
    "    val_labels: List of validation summary texts (optional)\n",
    "    test_texts: List of test article texts (optional)\n",
    "    test_labels: List of test summary texts (optional)\n",
    "    \n",
    "  Returns:\n",
    "    Tuple of (train_dataset, val_dataset, test_dataset, tokenizer)\n",
    "  \"\"\"\n",
    "  # Load Pegasus tokenizer\n",
    "  tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "  # Check if validation and test sets are provided\n",
    "  prepare_val = False if val_texts is None or val_labels is None else True\n",
    "  prepare_test = False if test_texts is None or test_labels is None else True\n",
    "\n",
    "  def tokenize_data(texts, labels):\n",
    "    \"\"\"\n",
    "    Tokenize articles and summaries.\n",
    "    \n",
    "    Args:\n",
    "      texts: List of article texts\n",
    "      labels: List of summary texts\n",
    "      \n",
    "    Returns:\n",
    "      PegasusDataset instance with tokenized data\n",
    "    \"\"\"\n",
    "    # Tokenize inputs (articles)\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "    # Tokenize targets (summaries)\n",
    "    decodings = tokenizer(labels, truncation=True, padding=True)\n",
    "    # Create dataset\n",
    "    dataset_tokenized = PegasusDataset(encodings, decodings)\n",
    "    return dataset_tokenized\n",
    "\n",
    "  # Tokenize all datasets\n",
    "  train_dataset = tokenize_data(train_texts, train_labels)\n",
    "  val_dataset = tokenize_data(val_texts, val_labels) if prepare_val else None\n",
    "  test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
    "\n",
    "  return train_dataset, val_dataset, test_dataset, tokenizer\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute ROUGE metrics for model evaluation.\n",
    "    \n",
    "    This function is called automatically during validation.\n",
    "    It decodes predictions and references, then computes ROUGE scores.\n",
    "    \n",
    "    Args:\n",
    "        eval_pred: Predictions and labels from the model\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of metric scores (ROUGE-1, ROUGE-2, ROUGE-L, ROUGE-Lsum, gen_len)\n",
    "    \"\"\"\n",
    "    # Load ROUGE metric\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    \n",
    "    # Extract predictions and labels\n",
    "    predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "\n",
    "    # Decode predictions (convert token IDs back to text)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 (ignored tokens) with pad token before decoding\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_result = rouge.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        use_stemmer=True,  # Use stemming for better matching\n",
    "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]  # Compute these ROUGE variants\n",
    "    )\n",
    "    \n",
    "    # Calculate average generated summary length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    rouge_result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    # Log metrics to TensorBoard for visualization\n",
    "    for k, v in rouge_result.items():\n",
    "        writer.add_scalar(f\"eval/{k}\", v, trainer.state.global_step)\n",
    "\n",
    "    # Return metrics dictionary\n",
    "    return {k: v for k, v in rouge_result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 6815953,
     "status": "ok",
     "timestamp": 1765148351199,
     "user": {
      "displayName": "Laurent Arifaj",
      "userId": "09689383856083908659"
     },
     "user_tz": -60
    },
    "id": "SvN3sG6Ixhio",
    "outputId": "d8ea1d06-4042-4797-9a21-46b69267ac54"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv(f\"{DRIVE_DATA_PATH}/train.csv\").head(10000)\n",
    "val_df = pd.read_csv(f\"{DRIVE_DATA_PATH}/val.csv\").head(2000)\n",
    "\n",
    "\n",
    "dataset_train = Dataset.from_pandas(train_df)\n",
    "dataset_valid = Dataset.from_pandas(val_df)\n",
    "train_texts, train_labels = dataset_train[CLEAN_TEXT_COLUMN], dataset_train[SUMMARY_COLUMN]\n",
    "valid_texts, valid_labels = dataset_valid[CLEAN_TEXT_COLUMN], dataset_valid[SUMMARY_COLUMN]\n",
    "\n",
    "\n",
    "print(\"Train:\", len(train_texts))\n",
    "print(\"Val:\", len(valid_texts))\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, tokenizer = prepare_data(MODEL, train_texts, train_labels, valid_texts, valid_labels)\n",
    "trainer = prepare_fine_tuning(MODEL, tokenizer, train_dataset, val_dataset=val_dataset)\n",
    "trainer.train()\n",
    "trainer.add_callback(GpuLoggerCallback(writer))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOnFKyt/0BscAgHsYFE2Fjw",
   "gpuType": "A100",
   "provenance": [
    {
     "file_id": "1Fn3Kbw541EDoimsh8LKFdKJWKpiZLf_6",
     "timestamp": 1765067147996
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
